import numpy as np
import random
GRID = 5
start = (0, 0)
destination = (4, 4)
traffic_lights = {(2, 2): "RED", (1, 3): "GREEN"}

actions = {
    0: (-1, 0),
    1: (1, 0),
    2: (0, -1),
    3: (0, 1),
    4: (0, 0)
}

def valid_move(pos):
    return 0 <= pos[0] < GRID and 0 <= pos[1] < GRID

def step(state, action):
    r, c = state
    dr, dc = actions[action]
    new_state = (r + dr, c + dc)

    if not valid_move(new_state):
        return state, -5, False

    if new_state in traffic_lights and traffic_lights[new_state] == "RED":
        return state, -3, False
    if new_state == destination:
        return new_state, 20, True

    return new_state, -1, False
def random_policy():
    return random.choice(list(actions.keys()))

def greedy_policy(state):
    r, c = state
    dr = destination[0] - r
    dc = destination[1] - c

    if abs(dr) > abs(dc):
        return 1 if dr > 0 else 0
    else:
        return 3 if dc > 0 else 2

def safe_greedy_policy(state):
    action = greedy_policy(state)
    r, c = state
    dr, dc = actions[action]
    next_state = (r + dr, c + dc)

    if next_state in traffic_lights and traffic_lights[next_state] == "RED":
        return 4  # Stop
    return action
def run_episode(policy_func, max_steps=50):
    state = start
    total_reward = 0

    for _ in range(max_steps):
        action = policy_func(state)
        state, reward, done = step(state, action)
        total_reward += reward
        if done:
            break

    return total_reward, state == destination
episodes = 100

results = {
    "Random": [],
    "Greedy": [],
    "Safe-Greedy": []
}

for _ in range(episodes):
    results["Random"].append(run_episode(lambda s: random_policy())[1])
    results["Greedy"].append(run_episode(lambda s: greedy_policy(s))[1])
    results["Safe-Greedy"].append(run_episode(lambda s: safe_greedy_policy(s))[1])

print("Success Rate:")
for k in results:
    print(k, ":", sum(results[k]) / episodes)
