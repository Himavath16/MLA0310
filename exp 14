import numpy as np
import random
class ManufacturingEnv:
    def __init__(self):
        self.states = [0, 1, 2]     
        self.actions = [0, 1, 2]
        self.state = random.choice(self.states)

    def reset(self):
        self.state = random.choice(self.states)
        return self.state

    def step(self, action):
   
        if action == 2 and self.state == 0:
            reward = -5  
            next_state = 0
        elif self.state == 2 and action >= 1:
            reward = 5    
            next_state = 2
        else:
            reward = 2
            next_state = min(2, self.state + 1)

        done = False
        return next_state, reward, done
Q = np.zeros((3, 3))
alpha = 0.1
gamma = 0.9
epsilon = 0.2
episodes = 500

env = ManufacturingEnv()
for ep in range(episodes):
    state = env.reset()

    for step in range(20):
     
        if random.random() < epsilon:
            action = random.choice(env.actions)
        else:
            action = np.argmax(Q[state])

        next_state, reward, done = env.step(action)
        Q[state, action] += alpha * (
            reward + gamma * np.max(Q[next_state]) - Q[state, action]
        )

        state = next_state
settings = ["Low Speed", "Medium Speed", "High Speed"]
conditions = ["Poor", "Normal", "Optimal"]

print("Optimal Manufacturing Policy:\n")
for s in range(3):
    best_action = settings[np.argmax(Q[s])]
    print(f"Machine Condition: {conditions[s]} â†’ Setting: {best_action}")

print("\nLearned Q-Table:\n")
print(np.round(Q, 2))
